{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25bfef08",
   "metadata": {},
   "source": [
    "# 1. Resolver as dependÃªncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0580bf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: keras in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: keras-rl2 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: gym in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: ale-py in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (0.7.3)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (1.34.1)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.1.0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: six>=1.15.0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel>=0.35 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.2 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (1.21.2)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from keras) (1.7.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from keras) (6.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from gym) (2.0.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from ale-py) (5.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.6.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (58.0.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages (from importlib-resources->ale-py) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow keras keras-rl2 gym gym[atari] ale-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7022f433",
   "metadata": {},
   "source": [
    "# 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85107fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\ale_py\\roms\\__init__.py:94: DeprecationWarning: Automatic importing of atari-py roms won't be supported in future releases of ale-py. Please migrate over to using `ale-import-roms` OR an ALE-supported ROM package. To make this warning disappear you can run `ale-import-roms --import-from-pkg atari_py.atari_roms`.For more information see: https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management\n",
      "  _RESOLVED_ROMS = _resolve_roms()\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ale_py\n",
    "from random import randrange\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, SoftmaxPolicy, EpsGreedyQPolicy\n",
    "from rl.policy import GreedyQPolicy, BoltzmannQPolicy, MaxBoltzmannQPolicy, BoltzmannGumbelQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f9e6096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gym: 0.21.0\n",
      "ale_py: 0.7.3\n",
      "numpy: 1.21.2\n",
      "tensorflow: 2.5.0\n",
      "keras: 2.5.0\n"
     ]
    }
   ],
   "source": [
    "print('gym:', gym.__version__)\n",
    "print('ale_py:', ale_py.__version__)\n",
    "print('numpy:', np.__version__)\n",
    "print('tensorflow:', tf.__version__)\n",
    "print('keras:', keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a01ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basicamente precisamos dar acesso a memÃ³ria RAM para conseguir processar\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf05d951",
   "metadata": {},
   "source": [
    "ObtÃªm as Roms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c976356f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 10.6M    0 24551    0     0  17531      0  0:10:34  0:00:01  0:10:33 17536\n",
      "  1 10.6M    1  133k    0     0  53847      0  0:03:26  0:00:02  0:03:24 53838\n",
      "  2 10.6M    2  324k    0     0  96012      0  0:01:55  0:00:03  0:01:52 96026\n",
      "  5 10.6M    5  647k    0     0   140k      0  0:01:17  0:00:04  0:01:13  140k\n",
      "  8 10.6M    8  901k    0     0   163k      0  0:01:06  0:00:05  0:01:01  178k\n",
      " 10 10.6M   10 1153k    0     0   178k      0  0:01:00  0:00:06  0:00:54  222k\n",
      " 13 10.6M   13 1473k    0     0   193k      0  0:00:56  0:00:07  0:00:49  264k\n",
      " 15 10.6M   15 1730k    0     0   202k      0  0:00:53  0:00:08  0:00:45  275k\n",
      " 18 10.6M   18 1986k    0     0   207k      0  0:00:52  0:00:09  0:00:43  269k\n",
      " 20 10.6M   20 2241k    0     0   213k      0  0:00:50  0:00:10  0:00:40  269k\n",
      " 22 10.6M   22 2497k    0     0   218k      0  0:00:49  0:00:11  0:00:38  271k\n",
      " 25 10.6M   25 2754k    0     0   220k      0  0:00:49  0:00:12  0:00:37  262k\n",
      " 27 10.6M   27 3012k    0     0   224k      0  0:00:48  0:00:13  0:00:35  264k\n",
      " 30 10.6M   30 3329k    0     0   228k      0  0:00:47  0:00:14  0:00:33  270k\n",
      " 33 10.6M   33 3588k    0     0   231k      0  0:00:46  0:00:15  0:00:31  270k\n",
      " 35 10.6M   35 3842k    0     0   234k      0  0:00:46  0:00:16  0:00:30  270k\n",
      " 38 10.6M   38 4160k    0     0   239k      0  0:00:45  0:00:17  0:00:28  286k\n",
      " 40 10.6M   40 4423k    0     0   238k      0  0:00:45  0:00:18  0:00:27  275k\n",
      " 43 10.6M   43 4674k    0     0   240k      0  0:00:45  0:00:19  0:00:26  274k\n",
      " 45 10.6M   45 4996k    0     0   242k      0  0:00:44  0:00:20  0:00:24  273k\n",
      " 48 10.6M   48 5252k    0     0   243k      0  0:00:44  0:00:21  0:00:23  274k\n",
      " 50 10.6M   50 5506k    0     0   245k      0  0:00:44  0:00:22  0:00:22  266k\n",
      " 53 10.6M   53 5762k    0     0   245k      0  0:00:44  0:00:23  0:00:21  271k\n",
      " 56 10.6M   56 6094k    0     0   247k      0  0:00:43  0:00:24  0:00:19  274k\n",
      " 58 10.6M   58 6343k    0     0   248k      0  0:00:43  0:00:25  0:00:18  274k\n",
      " 60 10.6M   60 6597k    0     0   249k      0  0:00:43  0:00:26  0:00:17  273k\n",
      " 63 10.6M   63 6926k    0     0   250k      0  0:00:43  0:00:27  0:00:16  275k\n",
      " 65 10.6M   65 7169k    0     0   251k      0  0:00:43  0:00:28  0:00:15  278k\n",
      " 68 10.6M   68 7428k    0     0   252k      0  0:00:43  0:00:29  0:00:14  277k\n",
      " 71 10.6M   71 7745k    0     0   253k      0  0:00:42  0:00:30  0:00:12  278k\n",
      " 73 10.6M   73 8001k    0     0   253k      0  0:00:42  0:00:31  0:00:11  273k\n",
      " 76 10.6M   76 8260k    0     0   254k      0  0:00:42  0:00:32  0:00:10  273k\n",
      " 78 10.6M   78 8514k    0     0   254k      0  0:00:42  0:00:33  0:00:09  274k\n",
      " 81 10.6M   81 8833k    0     0   255k      0  0:00:42  0:00:34  0:00:08  273k\n",
      " 83 10.6M   83 9090k    0     0   256k      0  0:00:42  0:00:35  0:00:07  273k\n",
      " 85 10.6M   85 9345k    0     0   255k      0  0:00:42  0:00:36  0:00:06  270k\n",
      " 88 10.6M   88 9609k    0     0   256k      0  0:00:42  0:00:37  0:00:05  271k\n",
      " 90 10.6M   90 9864k    0     0   256k      0  0:00:42  0:00:38  0:00:04  270k\n",
      " 93 10.6M   93  9.9M    0     0   257k      0  0:00:42  0:00:39  0:00:03  270k\n",
      " 96 10.6M   96 10.1M    0     0   257k      0  0:00:42  0:00:40  0:00:02  266k\n",
      " 98 10.6M   98 10.4M    0     0   257k      0  0:00:42  0:00:41  0:00:01  273k\n",
      "100 10.6M  100 10.6M    0     0   259k      0  0:00:41  0:00:41 --:--:--  282k\n",
      "tar: Error opening archive: Failed to open 'lfw.tgz'\n",
      "JÃ¡ existe uma subpasta ou um arquivo rars.\n",
      "'mv' nÃ£o Ã© reconhecido como um comando interno\n",
      "ou externo, um programa operÃ¡vel ou um arquivo em lotes.\n",
      "'mv' nÃ£o Ã© reconhecido como um comando interno\n",
      "ou externo, um programa operÃ¡vel ou um arquivo em lotes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying adventure.bin from rars\\Adventure (1980) (Atari, Warren Robinett) (CX2613, CX2613P) (PAL).bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\adventure.bin\n",
      "copying air_raid.bin from rars\\Air Raid (Men-A-Vision) (PAL) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\air_raid.bin\n",
      "copying alien.bin from rars\\Alien (1982) (20th Century Fox Video Games, Douglas 'Dallas North' Neubauer) (11006) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\alien.bin\n",
      "copying amidar.bin from rars\\Amidar (1982) (Parker Brothers, Ed Temple) (PB5310) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\amidar.bin\n",
      "copying assault.bin from rars\\Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\assault.bin\n",
      "copying asterix.bin from rars\\Asterix (AKA Taz) (07-27-1983) (Atari, Jerome Domurat, Steve Woita) (CX2696) (Prototype).bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\asterix.bin\n",
      "copying asteroids.bin from rars\\Asteroids (1981) (Atari, Brad Stewart - Sears) (CX2649 - 49-75163) [no copyright] ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\asteroids.bin\n",
      "copying atlantis.bin from rars\\Atlantis (Lost City of Atlantis) (1982) (Imagic, Dennis Koble) (720103-1A, 720103-1B, IA3203, IX-010-04) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\atlantis.bin\n",
      "copying bank_heist.bin from rars\\Bank Heist (Bonnie & Clyde, Cops 'n' Robbers, Hold-Up, Roaring 20's) (1983) (20th Century Fox Video Games, Bill Aspromonte) (11012) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\bank_heist.bin\n",
      "copying battle_zone.bin from rars\\Battlezone (1983) (Atari - GCC, Mike Feinstein, Brad Rice) (CX2681) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\battle_zone.bin\n",
      "copying beam_rider.bin from rars\\Beamrider (1984) (Activision - Cheshire Engineering, David Rolfe, Larry Zwick) (AZ-037-04) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\beam_rider.bin\n",
      "copying berzerk.bin from rars\\Berzerk (1982) (Atari, Dan Hitchens - Sears) (CX2650 - 49-75168) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\berzerk.bin\n",
      "copying bowling.bin from rars\\Bowling (1979) (Atari, Larry Kaplan - Sears) (CX2628 - 6-99842, 49-75117) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\bowling.bin\n",
      "copying boxing.bin from rars\\Boxing - La Boxe (1980) (Activision, Bob Whitehead) (AG-002, CAG-002, AG-002-04) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\boxing.bin\n",
      "copying breakout.bin from rars\\Breakout - Breakaway IV (Paddle) (1978) (Atari, Brad Stewart - Sears) (CX2622 - 6-99813, 49-75107) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\breakout.bin\n",
      "copying carnival.bin from rars\\Carnival (1982) (Coleco - Woodside Design Associates, Steve 'Jessica Stevens' Kitchen) (2468) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\carnival.bin\n",
      "copying centipede.bin from rars\\Centipede (1983) (Atari - GCC) (CX2676) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\centipede.bin\n",
      "copying chopper_command.bin from rars\\Chopper Command (1982) (Activision, Bob Whitehead) (AX-015, AX-015-04) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\chopper_command.bin\n",
      "copying crazy_climber.bin from rars\\Crazy Climber (1983) (Atari - Roklan, Joe Gaucher, Alex Leavens) (CX2683) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\crazy_climber.bin\n",
      "copying defender.bin from rars\\Defender (1982) (Atari, Robert C. Polaro, Alan J. Murphy - Sears) (CX2609 - 49-75186) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\defender.bin\n",
      "copying demon_attack.bin from rars\\Demon Attack (Death from Above) (1982) (Imagic, Rob Fulop) (720000-200, 720101-1B, 720101-1C, IA3200, IA3200C, IX-006-04) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\demon_attack.bin\n",
      "copying donkey_kong.bin from rars\\Donkey Kong (1982) (Coleco - Woodside Design Associates - Imaginative Systems Software, Garry Kitchen) (2451) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\donkey_kong.bin\n",
      "copying double_dunk.bin from rars\\Double Dunk (Super Basketball) (1989) (Atari, Matthew L. Hubbard) (CX26159) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\double_dunk.bin\n",
      "copying elevator_action.bin from rars\\Elevator Action (1983) (Atari, Dan Hitchens) (CX26126) (Prototype) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\elevator_action.bin\n",
      "copying enduro.bin from rars\\Enduro (1983) (Activision, Larry Miller) (AX-026, AX-026-04) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\enduro.bin\n",
      "copying fishing_derby.bin from rars\\Fishing Derby (1980) (Activision, David Crane) (AG-004) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\fishing_derby.bin\n",
      "copying freeway.bin from rars\\Freeway (1981) (Activision, David Crane) (AG-009, AG-009-04) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\freeway.bin\n",
      "copying frogger.bin from rars\\Frogger (1982) (Parker Brothers, Ed English, David Lamkins) (PB5300) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\frogger.bin\n",
      "copying frostbite.bin from rars\\Frostbite (1983) (Activision, Steve Cartwright) (AX-031) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\frostbite.bin\n",
      "copying galaxian.bin from rars\\Galaxian (1983) (Atari - GCC, Mark Ackerman, Tom Calderwood, Glenn Parker) (CX2684) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\galaxian.bin\n",
      "copying gopher.bin from rars\\Gopher (Gopher Attack) (1982) (U.S. Games Corporation - JWDA, Sylvia Day, Todd Marshall, Robin McDaniel, Henry Will IV) (VC2001) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\gopher.bin\n",
      "copying gravitar.bin from rars\\Gravitar (1983) (Atari, Dan Hitchens, Mimi Nyden) (CX2685) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\gravitar.bin\n",
      "copying hero.bin from rars\\H.E.R.O. (1984) (Activision, John Van Ryzin) (AZ-036-04) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\hero.bin\n",
      "copying ice_hockey.bin from rars\\Ice Hockey - Le Hockey Sur Glace (1981) (Activision, Alan Miller) (AX-012, CAX-012, AX-012-04) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\ice_hockey.bin\n",
      "copying jamesbond.bin from rars\\James Bond 007 (James Bond Agent 007) (1984) (Parker Brothers - On-Time Software, Joe Gaucher, Louis Marbel) (PB5110) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\jamesbond.bin\n",
      "copying journey_escape.bin from rars\\Journey Escape (1983) (Data Age, J. Ray Dettling) (112-006) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\journey_escape.bin\n",
      "copying kaboom.bin from rars\\Kaboom! (Paddle) (1981) (Activision, Larry Kaplan, David Crane) (AG-010, AG-010-04) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\kaboom.bin\n",
      "copying kangaroo.bin from rars\\Kangaroo (1983) (Atari - GCC, Kevin Osborn) (CX2689) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\kangaroo.bin\n",
      "copying keystone_kapers.bin from rars\\Keystone Kapers - Raueber und Gendarm (1983) (Activision, Garry Kitchen - Ariola) (EAX-025, EAX-025-04I - 711 025-725) (PAL).bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\keystone_kapers.bin\n",
      "copying king_kong.bin from rars\\King Kong (1982) (Tigervision - Software Electronics Corporation, Karl T. Olinger - Teldec) (7-001 - 3.60001 VE) (PAL).bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\king_kong.bin\n",
      "copying koolaid.bin from rars\\Kool-Aid Man (Kool Aid Pitcher Man) (1983) (M Network, Stephen Tatsumi, Jane Terjung - Kool Aid) (MT4648) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\koolaid.bin\n",
      "copying krull.bin from rars\\Krull (1983) (Atari, Jerome Domurat, Dave Staugas) (CX2682) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\krull.bin\n",
      "copying kung_fu_master.bin from rars\\Kung-Fu Master (1987) (Activision - Imagineering, Dan Kitchen, Garry Kitchen) (AG-039-04) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\kung_fu_master.bin\n",
      "copying laser_gates.bin from rars\\Laser Gates (AKA Innerspace) (1983) (Imagic, Dan Oliver) (720118-2A, 13208, EIX-007-04I) (PAL).bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\laser_gates.bin\n",
      "copying lost_luggage.bin from rars\\Lost Luggage (Airport Mayhem) (1982) (Apollo - Games by Apollo, Larry Minor, Ernie Runyon, Ed Salvo) (AP-2004) [no opening scene] ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\lost_luggage.bin\n",
      "copying montezuma_revenge.bin from rars\\Montezuma's Revenge - Featuring Panama Joe (1984) (Parker Brothers - JWDA, Henry Will IV) (PB5760) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\montezuma_revenge.bin\n",
      "copying mr_do.bin from rars\\Mr. Do! (1983) (CBS Electronics, Ed English) (4L4478) (PAL).bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\mr_do.bin\n",
      "copying ms_pacman.bin from rars\\Ms. Pac-Man (1983) (Atari - GCC, Mark Ackerman, Glenn Parker) (CX2675) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\ms_pacman.bin\n",
      "copying name_this_game.bin from rars\\Name This Game (Guardians of Treasure) (1983) (U.S. Games Corporation - JWDA, Roger Booth, Sylvia Day, Ron Dubren, Todd Marshall, Robin McDaniel, Wes Trager, Henry Will IV) (VC1007) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\name_this_game.bin\n",
      "copying pacman.bin from rars\\Pac-Man (1982) (Atari, Tod Frye) (CX2646) (PAL).bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\pacman.bin\n",
      "copying phoenix.bin from rars\\Phoenix (1983) (Atari - GCC, Mike Feinstein, John Mracek) (CX2673) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\phoenix.bin\n",
      "copying video_pinball.bin from rars\\Pinball (AKA Video Pinball) (Zellers).bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\video_pinball.bin\n",
      "copying pitfall.bin from rars\\Pitfall! - Pitfall Harry's Jungle Adventure (Jungle Runner) (1982) (Activision, David Crane) (AX-018, AX-018-04) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\pitfall.bin\n",
      "copying pooyan.bin from rars\\Pooyan (1983) (Konami) (RC 100-X 02) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\pooyan.bin\n",
      "copying private_eye.bin from rars\\Private Eye (1984) (Activision, Bob Whitehead) (AG-034-04) ~.bin to C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\atari_roms\\private_eye.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\import_roms.py\", line 93, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\import_roms.py\", line 89, in main\n",
      "    import_roms(args.dirpath)\n",
      "  File \"C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\atari_py\\import_roms.py\", line 74, in import_roms\n",
      "    with open(filepath, \"rb\") as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'rars\\\\Pursuit of the Pink Panther (Pink Panther - The Video Game, Adventures of the Pink Panther) (1983) (Probe 2000 - NAP, Roger Booth, Todd Marshall, Robin McDaniel, Jim Wickstead) (3152VC) (Prototype) ~.bin'\n"
     ]
    }
   ],
   "source": [
    "!curl -O \"http://www.atarimania.com/roms/Roms.rar\"\n",
    "!tar -xzvf lfw.tgz\n",
    "!mkdir rars\n",
    "!mv HC\\ ROMS.zip   rars\n",
    "!mv ROMS.zip  rars\n",
    "!python -m atari_py.import_roms rars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18cde11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = 'MsPacman-ram-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "375460f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(ENV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4275e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOOP',\n",
       " 'UP',\n",
       " 'RIGHT',\n",
       " 'LEFT',\n",
       " 'DOWN',\n",
       " 'UPRIGHT',\n",
       " 'UPLEFT',\n",
       " 'DOWNRIGHT',\n",
       " 'DOWNLEFT']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.get_action_meanings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6068a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para facilitar removemos as aÃ§Ãµes: UPRIGHT, UPLEFT, DOWNRIGHT e DOWNLEFT\n",
    "actions = env.action_space.n - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66e0a24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:2 Score:170.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "env.reset()\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "episodes = 2\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        img.set_data(env.render(mode='rgb_array'))\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        action = randrange(actions)\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "        env.step(action)\n",
    "        env.step(action)\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdd713b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "env.seed(seed)\n",
    "max_steps_per_episode = 150000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f1c11c",
   "metadata": {},
   "source": [
    "# 3. Cria Deep Learning Model com Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b59028be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(env, actions):\n",
    "    model = keras.Sequential()\n",
    "    model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ab7c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(env, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e07838",
   "metadata": {},
   "source": [
    "# 4. Cria Agent com Keras-RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "099963e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1.,\n",
    "                                  value_min=.1, value_test=.05,\n",
    "                                  nb_steps=max_steps_per_episode)\n",
    "    \n",
    "    memory = SequentialMemory(limit=5000, window_length=1)\n",
    "\n",
    "    dqn = DQNAgent(model=model,\n",
    "                   memory=memory,\n",
    "                   policy=policy,\n",
    "                   nb_actions=actions,\n",
    "                   nb_steps_warmup=50000,\n",
    "                   target_model_update=10000,\n",
    "                   gamma=.99,\n",
    "                   train_interval=4,\n",
    "                   delta_clip=1.)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0a19f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = build_agent(model, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d842023",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.compile(Adam(learning_rate=.00025), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce3819",
   "metadata": {},
   "source": [
    "# 5. Treina "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a12ea3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 150000 steps ...\n",
      "Interval 1 (0 steps performed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 25s 2ms/step - reward: 0.3050\n",
      "15 episodes - episode_reward: 192.000 [110.000, 430.000] - lives: 2.072\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 24s 2ms/step - reward: 0.3550\n",
      "17 episodes - episode_reward: 208.235 [120.000, 580.000] - lives: 2.063\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 23s 2ms/step - reward: 0.3140\n",
      "17 episodes - episode_reward: 187.647 [110.000, 480.000] - lives: 2.087\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 25s 3ms/step - reward: 0.3740\n",
      "17 episodes - episode_reward: 222.353 [100.000, 500.000] - lives: 2.081\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 25s 2ms/step - reward: 0.3310: 0\n",
      "15 episodes - episode_reward: 218.667 [90.000, 330.000] - lives: 2.122\n",
      "\n",
      "Interval 6 (50000 steps performed)\n",
      "10000/10000 [==============================] - 67s 7ms/step - reward: 0.4000\n",
      "15 episodes - episode_reward: 274.667 [170.000, 630.000] - loss: 1.697 - mae: 33.270 - mean_q: 42.722 - mean_eps: 0.670 - lives: 2.054\n",
      "\n",
      "Interval 7 (60000 steps performed)\n",
      "10000/10000 [==============================] - 67s 7ms/step - reward: 0.4100\n",
      "15 episodes - episode_reward: 266.000 [140.000, 590.000] - loss: 0.930 - mae: 33.469 - mean_q: 42.311 - mean_eps: 0.610 - lives: 2.052\n",
      "\n",
      "Interval 8 (70000 steps performed)\n",
      "10000/10000 [==============================] - 67s 7ms/step - reward: 0.4050\n",
      "15 episodes - episode_reward: 271.333 [130.000, 900.000] - loss: 0.745 - mae: 33.412 - mean_q: 42.095 - mean_eps: 0.550 - lives: 2.124\n",
      "\n",
      "Interval 9 (80000 steps performed)\n",
      "10000/10000 [==============================] - 67s 7ms/step - reward: 0.4120\n",
      "15 episodes - episode_reward: 274.667 [180.000, 600.000] - loss: 0.686 - mae: 34.011 - mean_q: 42.754 - mean_eps: 0.490 - lives: 2.022\n",
      "\n",
      "Interval 10 (90000 steps performed)\n",
      "10000/10000 [==============================] - 67s 7ms/step - reward: 0.4460\n",
      "14 episodes - episode_reward: 315.000 [200.000, 610.000] - loss: 0.637 - mae: 34.465 - mean_q: 43.260 - mean_eps: 0.430 - lives: 2.060\n",
      "\n",
      "Interval 11 (100000 steps performed)\n",
      "10000/10000 [==============================] - 67s 7ms/step - reward: 0.5800\n",
      "14 episodes - episode_reward: 421.429 [120.000, 1140.000] - loss: 0.646 - mae: 34.163 - mean_q: 42.831 - mean_eps: 0.370 - lives: 1.968\n",
      "\n",
      "Interval 12 (110000 steps performed)\n",
      "10000/10000 [==============================] - 67s 7ms/step - reward: 0.4970\n",
      "15 episodes - episode_reward: 326.000 [190.000, 710.000] - loss: 0.675 - mae: 33.659 - mean_q: 42.199 - mean_eps: 0.310 - lives: 2.078\n",
      "\n",
      "Interval 13 (120000 steps performed)\n",
      "10000/10000 [==============================] - 67s 7ms/step - reward: 0.6400\n",
      "14 episodes - episode_reward: 449.286 [110.000, 1740.000] - loss: 0.872 - mae: 34.116 - mean_q: 42.705 - mean_eps: 0.250 - lives: 2.084\n",
      "\n",
      "Interval 14 (130000 steps performed)\n",
      "10000/10000 [==============================] - 67s 7ms/step - reward: 0.5560\n",
      "13 episodes - episode_reward: 403.846 [150.000, 820.000] - loss: 0.670 - mae: 33.876 - mean_q: 42.421 - mean_eps: 0.190 - lives: 2.179\n",
      "\n",
      "Interval 15 (140000 steps performed)\n",
      "10000/10000 [==============================] - 68s 7ms/step - reward: 0.6330\n",
      "done, took 794.092 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24dada71b20>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=max_steps_per_episode, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7769aec3",
   "metadata": {},
   "source": [
    "# 6. Preserva dados do Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c3e18f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.save_weights('dqn_{}_weights.h5f'.format(ENV_NAME), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1202e91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 10 episodes ...\n",
      "Episode 1: reward: 140.000, steps: 708\n",
      "Episode 2: reward: 220.000, steps: 669\n",
      "Episode 3: reward: 140.000, steps: 685\n",
      "Episode 4: reward: 140.000, steps: 699\n",
      "Episode 5: reward: 180.000, steps: 698\n",
      "Episode 6: reward: 140.000, steps: 693\n",
      "Episode 7: reward: 240.000, steps: 774\n",
      "Episode 8: reward: 300.000, steps: 729\n",
      "Episode 9: reward: 140.000, steps: 694\n",
      "Episode 10: reward: 180.000, steps: 705\n",
      "182.0\n"
     ]
    }
   ],
   "source": [
    "scores = dqn.test(env, nb_episodes=10, visualize=False)\n",
    "print(np.mean(scores.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bafe86e",
   "metadata": {},
   "source": [
    "# 7. Recarrega dados do Treino na MemÃ³ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77acb348",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del dqn\n",
    "del env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0296005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(ENV_NAME)\n",
    "actions = env.action_space.n - 4\n",
    "states = env.observation_space.shape[0]\n",
    "model = build_model(env, actions)\n",
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(learning_rate=.00025), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "536ef645",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.load_weights('dqn_{}_weights.h5f'.format(ENV_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70f51be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 10 episodes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\gym\\envs\\atari\\environment.py:255: UserWarning: \u001b[33mWARN: We strongly suggest supplying `render_mode` when constructing your environment, e.g., gym.make(ID, render_mode='human'). Using `render_mode` provides access to proper scaling, audio support, and proper framerates.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\thiag\\anaconda3\\envs\\new_env\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] NÃ£o Ã© possÃ­vel alterar o modo de thread depois de o mesmo estar definido\n",
      "  warnings.warn(str(err))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: reward: 370.000, steps: 1153\n",
      "Episode 2: reward: 140.000, steps: 698\n",
      "Episode 3: reward: 190.000, steps: 693\n",
      "Episode 4: reward: 140.000, steps: 693\n",
      "Episode 5: reward: 140.000, steps: 702\n",
      "Episode 6: reward: 140.000, steps: 689\n",
      "Episode 7: reward: 170.000, steps: 756\n",
      "Episode 8: reward: 170.000, steps: 697\n",
      "Episode 9: reward: 290.000, steps: 696\n",
      "Episode 10: reward: 140.000, steps: 687\n"
     ]
    }
   ],
   "source": [
    "_ = dqn.test(env, nb_episodes=10, visualize=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8695e5aa",
   "metadata": {},
   "source": [
    "# Claramente precisa aumentar e muito o max_steps_per_episode para conseguir fazer com que o Agente consiga jogar como um ser humano"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
